# Single-Layer Neural Network with Stochastic Gradient Descent(SGD)

## Overview

This project implements a basic single-layer neural network trained using Stochastic Gradient Descent (SGD). The neural network uses the sigmoid activation function and is designed to classify binary inputs.

## Key Features

- **Sigmoid Activation**: Applies the sigmoid function to the weighted sum of inputs.
- **SGD Training**: Uses stochastic gradient descent to update weights.
- **Binary Classification**: Trains on a simple dataset with binary outcomes.

## Author

Samuel Giwa Boluwatife

## Reference

"Deep Learning With Machine Learning, Neural Networks, and Artificial Intelligence" by Phil Kim.